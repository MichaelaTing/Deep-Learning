# 机器学习策略

## 正交化

**正交化**（Orthogonalization）的核心在于每次调整只会影响模型某一方面的性能，而对其他功能没有影响。这种方法有助于更快更有效地进行机器学习模型的调试和优化。

- 如果模型在训练集上表现不好，可以尝试训练更大的神经网络或者换一种更好的优化算法（例如 Adam）；
- 如果模型在验证集上表现不好，可以进行正则化处理或者加入更多训练数据；
- 如果模型在测试集上表现不好，可以尝试使用更大的验证集进行验证；
- 如果模型在实际应用中表现不好，可能是因为测试集没有设置正确或者成本函数评估指标有误，需要改变测试集或成本函数。

## 评价指标

构建机器学习系统时，通过设置一个量化的**单值评价指标**，可以使我们根据这一指标比较不同超参数对应的模型的优劣，从而选择最优的那个模型。

对于二分类问题，常用的评价指标是**精确率**（Precision）和**召回率**（Recall）。实际应用中，通常使用综合了精确率和召回率的单值评价指标 F1 Score 来评价模型的好坏。F1 Score 其实就是精准率和召回率的**调和平均数（Harmonic Mean）**，比单纯的平均数效果要好。

如果我们还想要将分类器的运行时间也纳入考虑范围，将其和精确率、召回率组合成一个单值评价指标显然不那么合适。这时，我们可以将某些指标作为**优化指标（Optimizing Matric）**，寻求它们的最优值；而将某些指标作为**满足指标（Satisficing Matric）**，只要在一定阈值以内即可。

## 贝叶斯最优误差

当机器学习超过人的表现水平后，它的进步速度逐渐变得缓慢，最终性能无法超过某个理论上限，这个上限被称为**贝叶斯最优误差（Bayes Optimal Error）**。贝叶斯最优误差一般认为是理论上可能达到的最优误差。

因为人类对于一些自然感知问题的表现水平十分接近贝叶斯最优误差，所以当机器学习系统的表现超过人类后，就没有太多继续改善的空间了。也因此，只要建立的机器学习模型的表现还没达到人类的表现水平时，就可以通过各种手段来提升它。例如采用人工标记过的数据进行训练，通过人工误差分析了解为什么人能够正确识别，或者是进行偏差、方差分析。当模型的表现超过人类后，这些手段起的作用就微乎其微了。

通过与贝叶斯最优误差，或者说，与人类表现水平的比较，可以表明一个机器学习模型表现的好坏程度，由此判断后续操作应该注重于减小偏差还是减小方差。

模型在**训练集**上的误差与人类表现水平的差值被称作**可避免偏差（Avoidable Bias）**。可避免偏差低便意味着模型在训练集上的表现很好，而**训练集与验证集之间错误率的差值**越小，意味着模型在验证集与测试集上的表现和训练集同样好。如果**可避免偏差**大于**训练集与验证集之间错误率的差值**，之后的工作就应该专注于减小偏差；反之，就应该专注于减小方差。

总之，想让一个监督学习算法达到使用程度，应该做到以下两点：

1. 算法对训练集的拟合很好，可以看作可避免偏差很低；
2. 推广到验证集和测试集效果也很好，即方差不是很大。

<img title="" src="https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Structuring_Machine_Learning_Projects/Human-level.png" alt="Human-level" style="zoom: 67%;" width="557">

## 错误分析

进行错误分析时，应该观察错误标记的例子，看看**假阳性和假阴性**，统计属于不同错误类型的**错误数量**。在这个过程中，你可能会得到启发，归纳出新的错误类型。

有时会注意到数据集中有些样本被人为地错误标记（incorrectly labeled）了。如果是在训练集中，由于机器学习算法对于随机误差的**稳健性（Robust）**，只要这些出错的样本数量较小，且分布近似随机，就不必花费时间修正。

而如果出现在验证集或者测试集，则可以在进行误差分析时，通过**统计人为标记错误所占的百分比**，来大致分析这种情况对模型的识别准确率的影响，并**比较该比例的大小和其他错误类型的比例**，以此判断是否值得去将错误的标记进行修正，还是可以忽略。

当你决定在验证集和测试集上手动检查标签并进行修正时，有一些额外的方针和原则需要考虑：

- 在验证集和测试集上**同时使用同样的修正手段**，以保证验证集和测试集来自相同分布；
- 同时检查判断正确和判断错误的例子（通常不用这么做）；
- 在修正验证集和测试集时，鉴于训练集的分布不必和验证/测试集完全相同，可以不去修正训练集。

## 数据不匹配

在可能存在训练集和验证/测试集分布不一致的情况下，为了解决这个问题，我们可以再定义一个**训练-验证集（Training-dev Set）**。训练-验证集和训练集的分布相同（或者是训练集分割出的子集），但是不参与训练过程。

现在，我们有了*训练集*错误率、*训练-验证集*错误率，以及*验证集*错误率。其中，*训练集*错误率和*训练-验证集*错误率的差值反映了方差；而*训练-验证集*错误率和*验证集*错误率的差值反映了样本分布不一致的问题，从而说明**模型擅长处理的数据和我们关心的数据来自不同的分布**，我们称之为**数据不匹配**（Data Mismatch）问题。

这里有两条关于如何解决数据不匹配问题的建议：

- 做错误分析，尝试了解训练集和验证/测试集的具体差异；
- 尝试将训练数据调整得更像验证集，或者收集更多类似于验证/测试集的数据。

如果你打算将训练数据调整得更像验证集，可以使用的一种技术是**人工合成数据**。

## 迁移学习

**迁移学习**（Tranfer Learning）是通过将已训练好的神经网络模型的一部分网络结构应用到另一模型，将一个神经网络从某个任务中学到的知识和经验运用到另一个任务中，以显著提高学习任务的性能。

例如，我们将为猫识别器构建的神经网络迁移应用到放射科诊断中。因为猫识别器的神经网络已经学习到了有关图像的结构和性质等方面的知识，所以只要先删除神经网络中原有的输出层，加入新的输出层并随机初始化权重系数$W^{[L]}、b^{[L]}$，随后用新的训练集进行训练，就完成了以上的迁移学习。

如果新的数据集很小，可能只需要重新训练输出层前的最后一层的权重，即$W^{[L]}、b^{[L]}$，并保持其他参数不变；而如果有足够多的数据，可以只保留网络结构，重新训练神经网络中所有层的系数。这时初始权重由之前的模型训练得到，这个过程称为**预训练（Pre-Training）**，之后的权重更新过程称为**微调（Fine-Tuning）**。

在下述场合进行迁移学习是有意义的：

1. 两个任务有同样的输入（比如都是图像或者都是音频）；
2. **拥有更多数据的任务迁移到数据较少的任务**；
3. 某一任务的低层次特征（底层神经网络的某些功能）对另一个任务的学习有帮助。

## 多任务学习

迁移学习中的步骤是串行的；而**多任务学习**（Multi-Task Learning）使用单个神经网络模型，利用共享表示采用并行训练同时学习多个任务。多任务学习的基本假设是**多个任务之间具有相关性**，并且任务之间可以利用相关性相互促进。例如，属性分类中，抹口红和戴耳环有一定的相关性，单独训练的时候是无法利用这些信息，多任务学习则可以利用任务相关性联合提高多个属性分类的精度。

以汽车自动驾驶为例，需要实现的多任务是识别行人、车辆、交通标志和信号灯。如果在输入的图像中检测出车辆和交通标志，则输出的 y 为：

$$
y=\left[\begin{array}{l}
0 \\
1 \\
1 \\
0
\end{array}\right]
$$

<img title="" src="https://raw.githubusercontent.com/bighuang624/Andrew-Ng-Deep-Learning-notes/master/docs/Structuring_Machine_Learning_Projects/Multi-Task-Learning.png" alt="Multi-Task-Learning" style="zoom:67%;" width="608">

多任务学习是使用单个神经网络模型来实现多个任务。实际上，也可以分别构建多个神经网络来实现。多任务学习中可能存在训练样本 Y 某些标签空白的情况，这不会影响多任务学习模型的训练。多任务学习和 Softmax 回归看上去有些类似，容易混淆。它们的区别是，Softmax 回归的输出向量 y 中只有一个元素为 1；而多任务学习的输出向量 y 中可以有多个元素为 1。

在下述场合进行多任务学习是有意义的：

1. 训练的一组任务可以共用低层次特征；
2. **通常每个任务的数据量接近；**
3. 能够训练一个足够大的神经网络，以同时做好所有的工作。多任务学习会降低性能的唯一情况（即和为每个任务训练单个神经网络相比性能更低的情况）是神经网络不够大。

在多任务深度网络中，低层次信息的共享有助于减少计算量，同时共享表示层可以使得几个有共性的任务更好的结合相关性信息，任务特定层则可以单独建模任务特定的信息，实现共享信息和任务特定信息的统一。

在实践中，多任务学习的使用频率要远低于迁移学习。计算机视觉领域中的物体识别是一个多任务学习的例子。

## 端到端学习

在传统的机器学习分块模型中，每一个模块处理一种输入，然后其输出作为下一个模块的输入，构成一条流水线。而**端到端深度学习**（End-to-end Deep Learning）只用一个单一的神经网络模型来实现所有的功能。它将所有模块混合在一起，只关心输入和输出。

如果数据量较少，传统机器学习分块模型所构成的流水线效果会很不错。但如果训练样本足够大，并且训练出的神经网络模型足够复杂，那么端到端深度学习模型的性能会比传统机器学习分块模型更好。

优点：

- 只要有足够多的数据，剩下的全部交给一个足够大的神经网络。比起传统的机器学习分块模型，可能更能捕获数据中的任何统计信息，而不需要用固有的认知来进行分析；
- 所需手工设计的组件更少，简化设计工作流程；

缺点：

- 需要大量的数据；
- 排除了可能有用的人工设计组件；

根据以上分析，决定一个问题是否应用端到端学习的**关键点**是：是否有足够的数据，支持能够直接学习从 x 映射到 y 并且足够复杂的函数？
